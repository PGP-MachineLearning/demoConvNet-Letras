{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"CNN-Letras-2-Solo-Probar.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"pHefTSRioYTI","colab_type":"text"},"source":["# Demo ConvNet para identificar LETRAS & NÚMEROS (realiza sólo validación del modelo ya entrenada y grabado en Drive)\n","Se usa el dataset de imágenes obtenido de http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/"]},{"cell_type":"markdown","metadata":{"id":"wHqFl6eVom-x","colab_type":"text"},"source":["1) Cargar librerías:"]},{"cell_type":"code","metadata":{"id":"UTg3k5lHn6p5","colab_type":"code","colab":{}},"source":["# nota se debe indicar la versión 1 de TF para compatibilidad del código\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","print(tf.__version__)\n","\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Flatten\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import Activation\n","\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.preprocessing import image\n","from IPython.display import Image\n","\n","import os\n","import os.path\n","\n","import json\n","from keras.models import model_from_json\n","from keras.models import load_model\n","\n","import numpy as np \n","import matplotlib.pyplot as plt\n","\n","print (\"Librerías cargadas.\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Ly3kAM3qsLo","colab_type":"text"},"source":["2) Monta el Drive para poder acceder a los archivos:"]},{"cell_type":"code","metadata":{"id":"LdUm8v20sawT","colab_type":"code","colab":{}},"source":["# monta Google Drive:\n","# Nota: la primera vez se debe confirmar el uso logueandose en \"Google Drive File Stream\" y obteniendo código de autentificación.\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# directorio local en Google Drive\n","path = 'gdrive/My Drive/IA/demoConvNet-Letras'\n","\n","# define los nombres de los archivos a utilizar para leer/grabar el modelo\n","history_file_name = path + '/Model/CNN_L_history_dump_final.json'\n","weights_file_name = path + '/Model/CNN_L_model_final.h5'\n","model_json_file_name = path + '/Model/CNN_L_model_final.json'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C5GAvIFSu8Bh","colab_type":"text"},"source":["3) Carga el modelo ya entrenado:\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"9ctfIQMvn6p-","colab_type":"code","colab":{}},"source":["# carga modelo ya grabado de ConvNet\n","if os.path.isfile(model_json_file_name):\n","    classifier = load_model(weights_file_name)\n","\n","    if os.path.isfile(history_file_name):\n","      h = json.load(open(history_file_name, 'r'))\n","      print(\"Modelo cargado: [\", weights_file_name, \"], [\", history_file_name, \"] y [\", model_json_file_name, \"] \")\n","    else: \n","      print(\"No se encuentra modelo para cargar\")\n","else:   \n","    print(\"No se encuentra modelo para cargar\")\n","\n","# muestra el modelo cargado\n","print(classifier.summary())\n","\n","# carga la lista de clases si no está definida   \n","import csv\n","with open( path + '/Model/clasesLetrasNros.csv', mode='r') as csvfile:\n","    all_classes = list(csv.reader(csvfile))[0]\n","print('Definición de las clases: ', all_classes)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HI6Wi3l979If","colab_type":"text"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"sEKejgxz8JFG","colab_type":"text"},"source":["4) Muestra estadísticas y resultados del probar el modelo:"]},{"cell_type":"code","metadata":{"id":"Y0vtnxsuzCMC","colab_type":"code","colab":{}},"source":["from sklearn.metrics.classification import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","\n","# define función auxiliar para mostrar resultado de cada imágen\n","def testImage(file_name, image_sample, classDesired, showPredictOK):\n","    result = classifier.predict(image_sample)\n","    \n","    # identifica mejor\n","    bestPos = np.argmax(result, axis=1)\n","    clasPred = str(all_classes[int(bestPos)])\n","\n","    prediction = clasPred + \"\" + str(result[0][bestPos]) + \"\" \n","    if clasPred == classDesired:\n","      res = True      \n","    else:\n","      res = False\n","      prediction = prediction + \"!\"\n","\n","    # muestra resultados (solo con error)\n","    if ((not res) or showPredictOK):\n","      print(\"> \", file_name,\": \" , prediction)\n","      img = Image(file_name, width = \"80\", height = \"50\")\n","      display(img)\n","\n","    return res, clasPred\n","\n","# define función auxiliar para mostrar resultado de cada directorio\n","def testAllClass(classDesired):\n","  cantOK = 0\n","  cantNOK = 0\n","  predict_path = \"\".join([path, '/Letras/test/', str(classDesired)])\n","  print(\"\\n\")\n","  y_classReal = []\n","  y_classRes = []\n","  for file in os.listdir(predict_path):\n","      if not file.startswith('.'):\n","          file = predict_path + \"/\" + file\n","\n","          image_sample = image.load_img(file, target_size = (128, 128))\n","          image_sample = image.img_to_array(image_sample)\n","          image_sample = np.expand_dims(image_sample, axis = 0)\n","          \n","          result, clRes = testImage(file, image_sample, classDesired, False)\n","          if (result):\n","            cantOK = cantOK + 1\n","          else:\n","            cantNOK = cantNOK + 1\n","\n","          y_classReal.append(classDesired)\n","          y_classRes.append(clRes)\n","\n","  print(\"\\nTOTAL CLASS\", classDesired,\": \", cantOK+cantNOK, \": Detectado OK \", cantOK, \"imágenes - Detectado con Error \", cantNOK, \"imágenes.\")  \n","  print('con una Exactitud de %f' % accuracy_score(y_classReal, y_classRes))\n","\n","  return cantOK, cantNOK, y_classReal, y_classRes\n","\n","# procesa las imágenes de la carpeta <Test>\n","y_tests = []\n","y_preds = []\n","okGral = 0 \n","NokGral = 0\n","all_dirs = os.listdir(\"\".join([path, '/Letras/test']))\n","for each_dir in all_dirs:\n","  print(\"\\n--- Procesando \", each_dir)\n","  ok, nok, tests, preds = testAllClass(each_dir)\n","  print(\"\\n--------------------------------------------------------------------------------------------------------------- \")  \n","  okGral = ok + okGral \n","  NokGral = nok + NokGral\n","  y_tests.extend(tests)\n","  y_preds.extend(preds)\n","\n","\n","print(\"\\n===========================================================================================================================\")\n","print(\"\\n= TOTAL GENERAL \", okGral+NokGral, \": Detectado OK \", okGral, \"imágenes - Detectado con Error \", NokGral, \"imágenes.\\n\\n\")\n","\n"," \n","print('\\n= Exactitud: %f' % accuracy_score(y_tests, y_preds))\n","  \n","print('\\n= Matriz de Confusión: ')\n","print(confusion_matrix(y_tests, y_preds, all_classes))\n","\n","print(\"\\n= Reporte de Clasificación: \")\n","print(classification_report(y_tests, y_preds))\n","\n","print(\"\\n===========================================================================================================================\")\n"],"execution_count":0,"outputs":[]}]}