{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"CNN-Letras-1-Entrenar-y-Probar.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"pHefTSRioYTI","colab_type":"text"},"source":["# Demo ConvNet para identificar LETRAS & NÚMEROS (realiza el entrenamiento y validación del modelo)\n","Se usa el dataset de imágenes obtenido de http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/"]},{"cell_type":"markdown","metadata":{"id":"wHqFl6eVom-x","colab_type":"text"},"source":["1) Cargar librerías:"]},{"cell_type":"code","metadata":{"id":"UTg3k5lHn6p5","colab_type":"code","colab":{}},"source":["# nota se debe indicar la versión 1 de TF para compatibilidad del código\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","print(tf.__version__)\n","\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Flatten\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import Activation\n","\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.preprocessing import image\n","from IPython.display import Image\n","\n","import os\n","import os.path\n","\n","import json\n","from keras.models import model_from_json\n","from keras.models import load_model\n","\n","import numpy as np \n","import matplotlib.pyplot as plt\n","\n","print (\"Librerías cargadas.\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Ly3kAM3qsLo","colab_type":"text"},"source":["2) Cargar imágenes a procesar:"]},{"cell_type":"code","metadata":{"id":"LdUm8v20sawT","colab_type":"code","colab":{}},"source":["# monta Google Drive:\n","# Nota: la primera vez se debe confirmar el uso logueandose en \"Google Drive File Stream\" y obteniendo código de autentificación.\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# directorio local en Google Drive\n","path = 'gdrive/My Drive/IA/demoConvNet-Letras'\n","\n","# define los nombres de los archivos a utilizar para leer/grabar el modelo\n","history_file_name = path + '/Model/CNN_L_history_dump_final.json'\n","weights_file_name = path + '/Model/CNN_L_model_final.h5'\n","model_json_file_name = path + '/Model/CNN_L_model_final.json'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eGM4EBpNn6qK","colab_type":"code","colab":{}},"source":["# ajusta el tamaño para achicar los valores del RGB (que pasen a ser de 0 a 1 en vez de 0 a 255)\n","train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = False)\n","\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","# también se resizean las imagenes a 128x128\n","target_size = (128, 128)\n","batch_size = 500\n","\n","# levanta el nombre de las clases\n","all_classes = os.listdir(\"\".join([path, '/Letras/train/']))\n","print(\"Clases \",  len(all_classes), \": \", all_classes)\n","\n","# levanta imágenes de entrenamiento\n","print(\"\\nImágenes de entrenamiento: \")\n","training_set = train_datagen.flow_from_directory(\"\".join([path, '/Letras/train/']), \n","                                                 target_size=target_size, \n","                                                 batch_size=batch_size, \n","                                                 shuffle=True, \n","                                                 classes=all_classes,\n","                                                 class_mode=\"categorical\")\n","# levanta imágenes de prueba\n","print(\"\\nImágenes de prueba: \")\n","test_set = test_datagen.flow_from_directory(\"\".join([path, '/Letras/test/']), \n","                                            target_size=target_size, \n","                                            batch_size=batch_size,\n","                                            classes=all_classes,\n","                                            shuffle=True, \n","                                            class_mode=\"categorical\")\n","#print(training_set.class_indices)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R4WONumeo1hl","colab_type":"text"},"source":["3) Construye el modelo:"]},{"cell_type":"markdown","metadata":{"id":"341V1wqNS2fG","colab_type":"text"},"source":["- Define el modelo de cero (primera ejecución):"]},{"cell_type":"code","metadata":{"id":"PccxT6QEpBwL","colab_type":"code","colab":{}},"source":["# construye modelo de la nueva ConvNet\n","classifier = Sequential()\n","classifier.add(Conv2D(64, (3, 3), input_shape = (128, 128, 3), activation = 'relu'))\n","classifier.add(MaxPooling2D(pool_size = (2, 2)))\n","\n","classifier.add(Conv2D(64, (3, 3), activation = 'relu'))\n","classifier.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","classifier.add(Flatten())\n","\n","classifier.add(Dense(units = 64, activation = 'relu'))\n","classifier.add(Dropout(0.5))\n","\n","# genera una salida softmax por clase de imágenes detectada\n","classifier.add(Dense(units = len(training_set.class_indices), activation='softmax'))\n","\n","\n","# compila el modelo\n","classifier.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","\n","# muestra el modelo creado\n","print(classifier.summary())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pkTL7lGGS62o","colab_type":"text"},"source":["- Carga un modelo ya pre-entrenado (luego de primera ejecución):"]},{"cell_type":"code","metadata":{"id":"mNGGP1HKTFZN","colab_type":"code","colab":{}},"source":["# carga modelo ya grabado de ConvNet\n","if os.path.isfile(model_json_file_name):\n","    classifier = load_model(weights_file_name)\n","\n","    if os.path.isfile(history_file_name):\n","      h = json.load(open(history_file_name, 'r'))\n","      print(\"Modelo cargado: [\", weights_file_name, \"], [\", history_file_name, \"] y [\", model_json_file_name, \"] \")\n","    else: \n","      print(\"No se encuentra modelo para cargar\")\n","else:   \n","    print(\"No se encuentra modelo para cargar\")\n","\n","# muestra el modelo cargado\n","print(classifier.summary())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OZmeaWiZrT5H","colab_type":"text"},"source":["4) Entrenar el modelo:"]},{"cell_type":"code","metadata":{"id":"VrlDPmwjuahr","colab_type":"code","colab":{}},"source":["# parámetros\n","steps_per_epoch = 25 #50\n","epochs = 5\n","validation_steps = 15\n","\n","# define funciones especiales de \"callbacks\" \n","# que se ejecutan durante el entrenamiento\n","# para terminar antes si el accuracy no mejora\n","# y guardar mejores modelos generados (menor loss)\n","early_stop = EarlyStopping(monitor='acc',  # 'loss'\n","                           min_delta=0.001, \n","                           patience=3, \n","                           mode='max', # 'min'\n","                           verbose=1)\n","checkpoint = ModelCheckpoint(weights_file_name, \n","                             monitor='loss',                              \n","                             verbose=1, \n","                             save_best_only=True, \n","                             mode='min', \n","                             period=1)\n","\n","# manda a entrenar el modelo (conviene usar GPU)\n","history = classifier.fit_generator(training_set, \n","                      steps_per_epoch = steps_per_epoch, \n","                      epochs = epochs, \n","                      validation_data = test_set, \n","                      validation_steps = validation_steps,\n","                      callbacks = [early_stop,checkpoint])\n","\n","h = history.history"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JSQxRyuxpCZX","colab_type":"text"},"source":["4') Graba el modelo entrenado:\n","\n"]},{"cell_type":"code","metadata":{"id":"vnIChot0rhXA","colab_type":"code","colab":{}},"source":["# graba el modelo\n","\n","#classifier.save(weights_file_name) -- Se graba al hacer el entrenamiento\n","\n","model_json = classifier.to_json()\n","with open(model_json_file_name, \"w\") as json_file:\n","    json_file.write(model_json)\n","\n","with open(history_file_name, 'w') as f:\n","  json.dump(h, f)\n","\n","print(\"Modelo grabado: [\", weights_file_name, \"], [\", history_file_name, \"] y [\", model_json_file_name, \"] \")\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sEKejgxz8JFG","colab_type":"text"},"source":["5) Muestra estadísticas y resultados del probar el modelo:"]},{"cell_type":"code","metadata":{"id":"nv_3KJgln6qR","colab_type":"code","colab":{}},"source":["# muestra gráfico de exactitud y loss\n","plt.plot(h['acc'])\n","plt.plot(h['val_acc'])\n","plt.title('Exactitud del Modelo')\n","plt.ylabel('Exactitud')\n","plt.xlabel('Época')\n","plt.legend(['Entrenamiento', 'Validación'], loc='upper left')\n","plt.show()\n","\n","plt.plot(h['loss'])\n","plt.plot(h['val_loss'])\n","plt.title('Error del Modelo')\n","plt.ylabel('Loss')\n","plt.xlabel('Época')\n","plt.legend(['Entrenamiento', 'Validación'], loc='upper left')\n","plt.show()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y0vtnxsuzCMC","colab_type":"code","colab":{}},"source":["from sklearn.metrics.classification import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","\n","# define función auxiliar para mostrar resultado de cada imágen\n","def testImage(file_name, image_sample, classDesired, showPredictOK, showPredictError):\n","    result = classifier.predict(image_sample)\n","    \n","    # identifica mejor\n","    bestPos = np.argmax(result, axis=1)\n","    clasPred = str(all_classes[int(bestPos)])\n","\n","    prediction = \"\".join([clasPred, \"\", str(result[0][bestPos]), \"\" ])\n","    if clasPred == classDesired:\n","      res = True      \n","    else:\n","      res = False\n","      prediction = \"\".join([prediction, \"!\"])\n","\n","    # muestra resultados (solo con error)\n","    if (((not res) and showPredictError) or showPredictOK):\n","      print(\"> \", file_name,\": \" , prediction)\n","      img = Image(file_name, width = \"80\", height = \"50\")\n","      display(img)\n","\n","    return res, clasPred\n","\n","# define función auxiliar para mostrar resultado de cada directorio\n","def testAllClass(classDesired):\n","  cantOK = 0\n","  cantNOK = 0\n","  predict_path = \"\".join([path, '/Letras/test/', str(classDesired)])\n","  print(\"\\n\")\n","  y_classReal = []\n","  y_classRes = []\n","  for file in os.listdir(predict_path):\n","      if not file.startswith('.'):\n","          file = predict_path + \"/\" + file\n","\n","          image_sample = image.load_img(file, target_size = (128, 128))\n","          image_sample = image.img_to_array(image_sample)\n","          image_sample = np.expand_dims(image_sample, axis = 0)\n","          \n","          result, clRes = testImage(file, image_sample, classDesired, False, False)\n","          if (result):\n","            cantOK = cantOK + 1\n","          else:\n","            cantNOK = cantNOK + 1\n","\n","          y_classReal.append(classDesired)\n","          y_classRes.append(clRes)\n","\n","  print(\"\\nTOTAL CLASS\", classDesired,\": \", cantOK+cantNOK, \": Detectado OK \", cantOK, \"imágenes - Detectado con Error \", cantNOK, \"imágenes.\")  \n","  print('con una Exactitud de %f' % accuracy_score(y_classReal, y_classRes))\n","\n","  return cantOK, cantNOK, y_classReal, y_classRes\n","\n","# procesa las imágenes de la carpeta <Test>\n","y_tests = []\n","y_preds = []\n","okGral = 0 \n","NokGral = 0\n","all_dirs = os.listdir(\"\".join([path, '/Letras/test']))\n","for each_dir in all_dirs:\n","  print(\"\\n--- Procesando \", each_dir)\n","  ok, nok, tests, preds = testAllClass(each_dir)\n","  print(\"\\n--------------------------------------------------------------------------------------------------------------- \")  \n","  okGral = ok + okGral \n","  NokGral = nok + NokGral\n","  y_tests.extend(tests)\n","  y_preds.extend(preds)\n","\n","\n","print(\"\\n===========================================================================================================================\")\n","print(\"\\n= TOTAL GENERAL \", okGral+NokGral, \": Detectado OK \", okGral, \"imágenes - Detectado con Error \", NokGral, \"imágenes.\\n\\n\")\n","\n"," \n","print('\\n= Exactitud: %f' % accuracy_score(y_tests, y_preds))\n","  \n","print('\\n= Matriz de Confusión: ')\n","print(confusion_matrix(y_tests, y_preds, all_classes))\n","\n","print(\"\\n= Reporte de Clasificación: \")\n","print(classification_report(y_tests, y_preds))\n","\n","print(\"\\n===========================================================================================================================\")\n"],"execution_count":0,"outputs":[]}]}